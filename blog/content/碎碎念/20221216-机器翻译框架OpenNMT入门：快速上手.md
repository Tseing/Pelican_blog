title: æœºå™¨ç¿»è¯‘æ¡†æ¶ OpenNMT å…¥é—¨ï¼šå¿«é€Ÿä¸Šæ‰‹
slug: opennmt-tutorial-quickstart
date: 2022-12-16
tags: OpenNMT, NLP, Python
summary: æ‹†è§£é¡¹ç›®ä»£ç çš„æ—¶å€™å‘ç°ä½¿ç”¨åˆ°äº† onmt è¿™ä¸ªå¤æ€ªä¸œè¥¿ï¼ŒæŸ¥é˜…èµ„æ–™åæ‰çŸ¥é“è¿™æ˜¯ä¸€ä¸ªè‡ªç„¶æœºå™¨ç¿»è¯‘çš„æ¡†æ¶ï¼Œæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å¸¸ç”¨çš„å·¥å…·ã€‚ä½†æ˜¯ç›¸å…³èµ„æ–™åˆå¤ªå°‘ï¼Œäºæ˜¯ä¸å¾—ä¸ç…§ç€æ–‡æ¡£ä¸€ç‚¹ä¸€ç‚¹å•ƒï¼Œæœ€åç•™ä¸‹äº†è¿™ç¯‡ç¬”è®°ã€‚

æ‹†è§£é¡¹ç›®ä»£ç çš„æ—¶å€™å‘ç°ä½¿ç”¨åˆ°äº† `onmt` è¿™ä¸ªå¤æ€ªä¸œè¥¿ï¼ŒæŸ¥é˜…èµ„æ–™åæ‰çŸ¥é“è¿™æ˜¯ä¸€ä¸ªè‡ªç„¶æœºå™¨ç¿»è¯‘çš„æ¡†æ¶ï¼Œæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å¸¸ç”¨çš„å·¥å…·ã€‚ä½†æ˜¯ç›¸å…³èµ„æ–™åˆå¤ªå°‘ï¼Œäºæ˜¯ä¸å¾—ä¸ç…§ç€æ–‡æ¡£ä¸€ç‚¹ä¸€ç‚¹å•ƒï¼Œæœ€åç•™ä¸‹äº†è¿™ç¯‡ç¬”è®°ã€‚

OpenNMT å®˜æ–¹æè¿°è¯¥æ¡†æ¶ä¸º an open source neural machine translation systemï¼Œç‚¹è¿› [OpenNMT çš„å®˜ç½‘](https://opennmt.net/)å¯ä»¥çœ‹åˆ°æ›´å¤šèµ„æ–™ï¼Œå› æ­¤ä¹Ÿä¸éœ€è¦æˆ‘å¤šæè¿°ã€‚æ€»ç»“ä¸€ä¸‹å°±æ˜¯ï¼ŒOpenNMT æ˜¯æ­å»ºè‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹çš„å¼€æºæ¡†æ¶ï¼Œå…¶ä¸­è‡ªç„¶åŒ…æ‹¬å¸¸è§çš„ RNN å’Œ Transformer ç­‰æ¨¡å‹ã€‚å¦‚æœåœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢æœ‰éœ€è¦ï¼ŒOpenNMT ç»å¯¹æ˜¯ä¸€ä¸ªè½»é‡æœ‰æ•ˆçš„æ¡†æ¶ã€‚

OpenNMT çš„ä¸­æ–‡å­¦ä¹ èµ„æ–™è¾ƒå°‘ï¼Œäºæ˜¯æˆ‘åªèƒ½å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://opennmt.net/OpenNMT-py/main.html)å­¦ä¹ ã€‚åœ¨è¿™ç¯‡ç¬”è®°ä¸­ï¼Œæˆ‘ä¼šæŠŠæ–‡æ¡£ä¸­çš„æ¨¡å‹éƒ½è¯•éªŒä¸€éï¼ˆå¸Œæœ›åˆ«ğŸ•Šï¸ï¼‰ï¼Œè®°å½•ä¸‹æ•´ä¸ªè¿‡ç¨‹æˆ–è®¸èƒ½å¸®åŠ©åˆ°éœ€è¦çš„äººã€‚

## å‡†å¤‡å·¥ä½œ

é¦–å…ˆä»‹ç»ä¸€ä¸‹æˆ‘çš„è¿è¡Œç¯å¢ƒï¼Œæˆ‘çš„è®¾å¤‡æ­è½½ä¸€å— `GTX 1080` GPUï¼Œç³»ç»Ÿä¸º `Ubuntu 20.04`ï¼Œéœ€è¦æå‰åœ¨è®¾å¤‡ä¸Šå®‰è£…å¥½ CUDAï¼Œæˆ‘ä½¿ç”¨ Anaconda é…ç½® Python ç¯å¢ƒã€‚

{note begin}OpenNMT ä¸æ”¯æŒè¿‡æ—§çš„ GPUï¼Œä¹‹å‰åœ¨ `GTX 970` çš„è®¾å¤‡ä¸Šå°±æ— æ³•è®­ç»ƒæ¨¡å‹ï¼Œè¿™ä¸ªé—®é¢˜å¯èƒ½é™¤äº†æ¢è®¾å¤‡æ— è§£ğŸ˜­{note end}

## å¿«é€Ÿä¸Šæ‰‹

### å®‰è£… OpenNMT

OpenNMT æœ‰ PyTorch ä¸ TensorFlow ä¸¤ä¸ªç‰ˆæœ¬ï¼ŒPyTorch åœ¨ç¯å¢ƒæ­å»ºä¸Šæ–¹ä¾¿å¾ˆå¤šï¼Œæ‰€ä»¥æˆ‘é€‰æ‹© PyTorch ç‰ˆæœ¬ã€‚å…ˆåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œå†ç›´æ¥é€šè¿‡ `pip` å®‰è£… OpenNMT-pyï¼ŒPython ç‰ˆæœ¬ä¸º `3.9`ï¼ŒOpenNMT-py ä¸º `3.0.2`ã€‚

```sh
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n nlp python==3.9
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
conda activate nlp
# å®‰è£… OpenNMT
pip install OpenNMT-py==3.0.2
```

{note begin}å›½å†…ç›´è¿ PyPI çš„é€Ÿåº¦å¯èƒ½å¾ˆæ…¢ï¼Œå¯ä»¥ä½¿ç”¨æ¸…åæºï¼Œå‘½ä»¤ä¸º `pip install -i https://pypi.tuna.tsinghua.edu.cn/simple {some-package}`ï¼Œå°†å…¶ä¸­çš„ `{some-package}` æ›¿æ¢ä¸ºéœ€è¦å®‰è£…çš„åŒ…åç§°ã€‚{note end}

ç›´æ¥å®‰è£… `OpenNMT-py` å¾ˆæœ‰å¯èƒ½ä¼šæœ‰é—®é¢˜ï¼Œä¸»è¦åŸå› æ˜¯ Pytorch ä¸ CUDA ç‰ˆæœ¬ä¸åŒ¹é…ã€‚å¯ä»¥ç”¨ `nvcc -V` æŸ¥è¯¢ CUDA ç‰ˆæœ¬ï¼Œå†åœ¨ [Pytorch å®˜ç½‘](https://pytorch.org/get-started/previous-versions/)æ‰¾åˆ°ç›¸åº”çš„ç‰ˆæœ¬ã€‚ä¾‹å¦‚æˆ‘çš„ CUDA ç‰ˆæœ¬ä¸º `11.4`ï¼Œé‚£ä¹ˆå°±éœ€è¦é‡æ–°å®‰è£…ä»¥ä¸‹ç‰ˆæœ¬çš„åŒ…è§£å†³ä¾èµ–é—®é¢˜ï¼š

```sh
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113
```

### å‡†å¤‡æ•°æ®

å¿«é€Ÿä¸Šæ‰‹ä¸€èŠ‚æ­å»ºçš„æ˜¯ä¸€ä¸ªç®€å•çš„åŒè¯­ç¿»è¯‘æ¨¡å‹ï¼Œå› æ­¤éœ€è¦å‡†å¤‡ä¸¤ç§è¯­è¨€çš„æ•°æ®ï¼Œåˆ†åˆ«ä¸ºæºè¯­è¨€` src` å’Œç›®æ ‡è¯­è¨€ `tgt`ï¼Œæ•°æ®æ–‡ä»¶ä¸­æ¯è¡ŒåŒ…å«ä¸€å¥è¯ï¼Œä»¥ç©ºæ ¼åˆ†éš”ä¸åŒçš„è¯ã€‚å†è€ƒè™‘åˆ°è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œé‚£ä¹ˆä¸€å…±éœ€è¦ 4 ç§æ•°æ®æ–‡ä»¶ï¼š

- `src-train.txt`
- `tgt-train.txt`
- `src-val.txt`
- `tgt-val.txt`

{note begin}å¯ä»¥æƒ³è±¡åˆ°ï¼Œå¦‚æœå¤„ç†çš„æ˜¯è‹±è¯­ã€æ³•è¯­ç­‰ä»¥ç©ºæ ¼åˆ†éš”å•è¯çš„è¯­è¨€ï¼Œåªéœ€è¦å°†æ–‡æœ¬æ•°æ®å¤„ç†ä¸ºæ¯è¡Œä¸€å¥è¯çš„æ ¼å¼å³å¯ã€‚ä½†å¯¹äºæ±‰è¯­ã€æ—¥è¯­ç­‰ä¸ä»¥ç‰¹æ®Šæ ‡è®°åˆ†éš”è¯è¯­çš„è¯­è¨€ï¼Œæ•°æ®éœ€è¦ç»è¿‡é¢å¤–çš„åˆ†è¯æ­¥éª¤åæ‰å¯ä»¥ä½¿ç”¨ã€‚{note end}

å®˜æ–¹æä¾›äº†è‹±è¯­-å¾·è¯­çš„æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½ï¼š

```sh
wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz
tar xf toy-ende.tar.gz
```

ä¹Ÿå¯ä»¥åˆ° [<i class="fa-brands fa-github"></i> OpenNMT-py/data/](https://github.com/OpenNMT/OpenNMT-py/tree/master/data) åœ¨çº¿æŸ¥çœ‹æ•°æ®é•¿ä»€ä¹ˆæ ·å­ã€‚


æ¥ç€é€šè¿‡ `vim toy_en_de.yaml` åœ¨ç›®å½•ä¸‹åˆ›å»º `.yaml` é…ç½®æ–‡ä»¶ï¼Œå†…å®¹ä¸º

```yaml
# toy_en_de.yaml

## Where the samples will be written
save_data: toy-ende/run/example
## Where the vocab(s) will be written
src_vocab: toy-ende/run/example.vocab.src
tgt_vocab: toy-ende/run/example.vocab.tgt
# Prevent overwriting existing files in the folder
overwrite: False

# Corpus opts:
data:
    corpus_1:
        path_src: toy-ende/src-train.txt
        path_tgt: toy-ende/tgt-train.txt
    valid:
        path_src: toy-ende/src-val.txt
        path_tgt: toy-ende/tgt-val.txt
```

åˆ›å»ºæ–‡ä»¶åçš„æ–‡ä»¶ç»“æ„ä¸º

```sh
.
â”œâ”€â”€ toy-ende
â”‚   â”œâ”€â”€ src-test.txt
â”‚   â”œâ”€â”€ src-train.txt
â”‚   â”œâ”€â”€ src-val.txt
â”‚   â”œâ”€â”€ tgt-test.txt
â”‚   â”œâ”€â”€ tgt-train.txt
â”‚   â””â”€â”€ tgt-val.txt
â””â”€â”€ toy_en_de.yaml
```

è®¾ç½®å®Œæˆåï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹æ„å»ºè¯åº“ï¼š

```sh
onmt_build_vocab -config toy_en_de.yaml -n_sample 10000
```

å…¶ä¸­ `n_sample` è®¾å®šäº†ä»è¯­æ–™ä¸­è·å–å¤šå°‘è¡Œçš„æ•°æ®ç”¨äºæ„å»ºè¯åº“ã€‚

{note begin}è‹¥ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œéœ€è¦è¿›å…¥è™šæ‹Ÿç¯å¢ƒåæ‰èƒ½è¿è¡Œä¸Šè¿°å‘½ä»¤ï¼Œè‹¥ä½¿ç”¨ Anacondaï¼Œä¹Ÿéœ€è¦å…ˆæ¿€æ´»ç¯å¢ƒã€‚Pytorch ä¸ CUDA ç‰ˆæœ¬ä¸åŒ¹é…ä¼šå¯¼è‡´ `undefined symbol: cublasLtGetStatusString, version libcublasLt.so` é”™è¯¯ã€‚{note end}

### è®­ç»ƒæ¨¡å‹

è®­ç»ƒæ¨¡å‹ä¹Ÿååˆ†ç®€å•ï¼Œåœ¨ `.yaml` æ–‡ä»¶ä¸­è¿½åŠ ä»¥ä¸‹å†…å®¹ï¼š

```yaml
# Vocabulary files that were just created
src_vocab: toy-ende/run/example.vocab.src
tgt_vocab: toy-ende/run/example.vocab.tgt

# Train on a single GPU
world_size: 1
gpu_ranks: [0]

# Where to save the checkpoints
save_model: toy-ende/run/model
save_checkpoint_steps: 500
train_steps: 1000
valid_steps: 500
```

ä½¿ç”¨ `onmt_train -config toy_en_de.yaml` å¼€å§‹è®­ç»ƒï¼Œè¯¥é…ç½®ä¼šç”Ÿæˆé»˜è®¤çš„ 2 å±‚å…·æœ‰ 500 ä¸ªéšè—å•å…ƒçš„ LSTM æ¨¡å‹ã€‚

### æ¨¡å‹é¢„æµ‹

ä½¿ç”¨ç±»ä¼¼çš„å‘½ä»¤è¿›è¡Œæ¨¡å‹é¢„æµ‹ï¼Œæ¨¡å‹é¢„æµ‹èƒ½å¤Ÿå°†æ–‡æœ¬æ–‡ä»¶ä¸­çš„å†…å®¹ç¿»è¯‘å¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶ä¸­ï¼š

```
onmt_translate -model toy-ende/run/model_step_1000.pt -src toy-ende/src-test.txt -output toy-ende/pred_1000.txt -gpu 0 -verbose
```

- ä¸Šé¢çš„å‘½ä»¤ä½¿ç”¨äº†è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ `toy-ende/run/model_step_1000.pt`
- é¢„æµ‹ `toy-ende/src-test.txt` æµ‹è¯•é›†æ•°æ®
- å°†ç»“æœè¾“å‡ºåˆ° `toy-ende/pred_1000.txt`ï¼Œ
- `-gpu` æŒ‡å®šäº†ä½¿ç”¨çš„ GPU
- `-verbose` æŒ‡å®šåœ¨ç»ˆç«¯ä¸­è¾“å‡ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ç»“æœ

ä½¿ç”¨ `head -n 2 toy-ende/src-test.txt` å’Œ `head -n 2 toy-ende/pred_1000.txt` æŸ¥çœ‹ä¸€ä¸‹é¢„æµ‹ç»“æœï¼š

```txt
# test
Orlando Bloom and Miranda Kerr still love each other
Actors Orlando Bloom and Model Miranda Kerr want to go their separate ways .

# pred
Die <unk> der <unk> der <unk> , die die <unk> der <unk> â€¦â€¦
```

ç”±äºè®­ç»ƒæ—¶é—´å¾ˆçŸ­ï¼Œæ•°æ®é›†å¾ˆå°ï¼Œé¢„æµ‹ç»“æœä¸ä¼šå¥½ï¼Œå†åŠ ä¸Šä¸è®¤è¯†å¾·è¯­ï¼Œä¹Ÿæ— æ³•åˆ¤æ–­ç»“æœçš„ä¼˜åŠ£ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥å°è¯•åœ¨æ›´å¤§çš„ä¸­æ–‡è¯­æ–™ä¸Šè¿›è¡Œç¿»è¯‘ä»»åŠ¡ã€‚

## æ–‡è¨€ç¿»è¯‘

B ç«™ä¸Šæœ‰ä¸€ä¸ªå±•ç¤º OpenNMT çš„[è§†é¢‘](https://www.bilibili.com/video/BV1NL4y1t73c/?spm_id_from=333.337.search-card.all.click&vd_source=a5a1b5dd5c760997f9e16b7806d64651)ï¼Œå®åœ¨å¾ˆä¸é”™ã€‚è§†é¢‘ä¸­å±•ç¤ºçš„ç¿»è¯‘ä»»åŠ¡æ˜¯å°†ç™½è¯è¯‘ä¸ºæ–‡è¨€ï¼Œä¸ä»…ç›´è§‚è€Œä¸”ååˆ†æœ‰è¶£ï¼Œæˆ‘è§‰å¾—ç‰¹åˆ«é€‚åˆç”¨æ¥å…¥é—¨ï¼Œä½œè€…çš„ä»£ç ä¹Ÿå…¬å¼€åœ¨ [GitHub](https://github.com/qhduan/notebook_gist/blob/master/%E7%BF%BB%E8%AF%91%E5%8F%A4%E6%96%87.ipynb) ä¸Šï¼Œå¯ä»¥å’Œæœ¬æ–‡ç›¸äº’å‚ç…§ï¼Œæœ¬æ–‡ä¸­çš„ä»£ç ä¹Ÿå¯ä»¥åœ¨ [<i class="fa-brands fa-github"></i> Tseing/OpenNMT-wenyan ](https://github.com/Tseing/OpenNMT-wenyan) æ‰¾åˆ°ã€‚

### å‡†å¤‡æ•°æ®

ç™½è¯æ–‡ä¸æ–‡è¨€æ–‡çš„å¹³è¡Œè¯­æ–™æ¥è‡ªäº [<i class="fa-brands fa-github"></i> NiuTrans/Classical-Modern](https://github.com/NiuTrans/Classical-Modern)ï¼ŒåŒ…å«äº†å¤§é‡å†…å®¹ï¼š

``` txt
# Classical-Modern/source/
å…ƒå²  åŒ—é½ä¹¦  å—é½ä¹¦  åæ±‰ä¹¦  å¤ªå¹³å¹¿è®°  å®‹å²    æ–°äº”ä»£å²  æ—§äº”ä»£å²  æ˜å²  æ¢ä¹¦      æ±‰ä¹¦              è¾½å²  é™ˆä¹¦  é­ä¹¦
åŒ—å²  å—å²    å²è®°    å‘¨ä¹¦    å®‹ä¹¦      å¾éœå®¢  æ–°å”ä¹¦    æ—§å”ä¹¦    æ™‹ä¹¦  æ°´ç»æ³¨å…¨  çŸ­ç¯‡ç« å’Œèµ„æ²»é€šé‰´  é‡‘å²  éš‹ä¹¦
```

ä¸‹è½½æ•°æ®åå¯ä»¥å…ˆç”¨ `head Classical-Modern/source/å²è®°` ä¸ `head Classical-Modern/target/å²è®°ç¿»è¯‘` æŸ¥çœ‹ä¸€ä¸‹è¯­æ–™ï¼š

```txt
# å²è®°
å¾Œä¸ºå¤ªå¸¸ï¼Œåæ³•å½“æ­»ï¼Œèµå…ä¸ºåº¶äººã€‚
ä¸Šæ›°ï¼šå‰‘ï¼Œäººä¹‹æ‰€æ–½æ˜“ï¼Œç‹¬è‡³ä»Šä¹ï¼Ÿ
ç„¶ç»ˆä¸è‡ªæ˜ä¹Ÿã€‚
ç„¶äº¦æ— æ‰€æ¯ã€‚

# å²è®°ç¿»è¯‘
å› ä¸ºè§¦çŠ¯æ³•å¾‹åˆ¤å¤„æ­»åˆ‘ï¼Œçº³ç±³ç²Ÿå…¥å®˜èµç½ªåæˆäº†å¹³æ°‘ã€‚
æ™¯å¸è¯´ï¼šå‰‘æ˜¯äººä»¬æ‰€å–œçˆ±ä¹‹ç‰©ï¼Œå¾€å¾€ç”¨æ¥é€äººæˆ–äº¤æ¢ä»–ç‰©ï¼Œéš¾é“ä½ èƒ½ä¿å­˜åˆ°ç°åœ¨å—ï¼Ÿ
è¯´è¿‡åä»–ç»ˆç©¶ä¸å†åšå…¶ä»–è¾©è§£ã€‚
ç„¶åä¹Ÿæ²¡æœ‰è®²åˆ«äººçš„ä»€ä¹ˆåè¯ã€‚
```

åŸå§‹è¯­æ–™æ˜¯å°†æ–‡è¨€ç¿»è¯‘ä¸ºç™½è¯ï¼Œå› æ­¤ `source` ä¸­å­˜å‚¨äº†åŸæ–‡ï¼Œ`target` ä¸­å­˜å‚¨äº†ç¿»è¯‘ï¼Œæ¯è¡Œä¸€å¥è¯ï¼Œä¸¤ä¸ªæ–‡ä»¶ä¸€ä¸€å¯¹åº”ã€‚æˆ‘ä»¬éœ€è¦é¢„å¤„ç†æ•°æ®ï¼Œå°†æ‰€æœ‰æ–‡æœ¬éƒ½ä½œä¸ºæ•°æ®é›†ã€‚

```py
import os

source_root = 'Classical-Modern/source'
target_root = 'Classical-Modern/target'

for f in os.listdir(source_root):
    print("processing " + f)
    source_file = os.path.join(source_root, f)
    target_file = os.path.join(target_root, f + 'ç¿»è¯‘')

    # ç»Ÿè®¡å„æ–‡æœ¬ä¸­è¡Œæ•°
    with open(source_file, "r", encoding="utf-8") as source_f:
        source_len = sum(1 for _ in source_f)
    with open(target_file, "r", encoding="utf-8") as target_f:
        target_len = sum(1 for _ in target_f)

    # å¯¹æ¯”å¹³è¡Œè¯­æ–™è¡Œæ•°ï¼Œç¡®ä¿ä¸€è‡´
    assert source_len == target_len
    try:
        with open('dataset/source_raw.txt', "a+", encoding="utf-8") as source_f:
            source_f.write(open(source_file, "r", encoding="utf-8").read())
        with open('dataset/target_raw.txt', "a+", encoding="utf-8") as target_f:
            target_f.write(open(target_file, "r", encoding="utf-8").read())
    except FileNotFoundError:
        os.mkdir('dataset')
```

æ£€æŸ¥ä¸€ä¸‹å¤„ç†çš„ç»“æœï¼š

```txt
# dataset/source_raw.txt
å¯†è®¡ä¸è¡Œã€‚
ä½¿è€…åˆ©é‡‘ï¼Œé‚ç›¸è®¸ã€‚
é£è¯´è¯¸å°è´¼ï¼Œæ‰€è‡³è¾„é™ï¼Œè®©å§‹æ•¬ç„‰ï¼Œå¬ä¸è®¡äº‹ã€‚
å®‡æ–‡æ¸©æ¯è°“å¯†æ›°ï¼šä¸æ€å…ƒçœŸï¼Œå…¬éš¾æœªå·²ã€‚

# dataset/target_raw.txt
æå¯†çš„æ„è§æ²¡æœ‰è¢«é‡‡çº³ã€‚
æŠ¼é€çš„äººè´ªå›¾é‡‘é’±ï¼Œä¾¿æ»¡å£ç­”åº”ã€‚
æ´¾äººæ¸¸è¯´å°è‚¡ä¹‰å†›ï¼Œè¢«åŠè¯´çš„äººéƒ½å½’é¡ºäº†ç¿Ÿè®©ï¼Œç¿Ÿè®©å¼€å§‹çœ‹é‡äº†ä»–ï¼Œå«ä»–åŒè‡ªå·±ä¸€èµ·è®¨è®ºé‡å¤§é—®é¢˜ã€‚
å®‡æ–‡æ¸©å¸¸å¯¹æå¯†è¯´ï¼šä¸æ€é‚´å…ƒçœŸï¼Œæ‚¨çš„ç¥¸å®³å°±ä¸ä¼šæ’é™¤ã€‚
```

æ¥ä¸‹æ¥è¦å¯¹æ–‡æœ¬åˆ†è¯ï¼Œå¯¹äºæ–‡è¨€æ–‡æ¥è¯´ï¼Œå•å­—è¯çš„å æ¯”éå¸¸é«˜ï¼Œå°†æ¯ä¸ªå•å­—ä½œä¸ºä¸€ä¸ªè¯å°±æ˜¯ä¸€ç§æ¯”è¾ƒæ–¹ä¾¿çš„åˆ†è¯æ–¹æ³•ï¼Œæ‰€ä»¥åœ¨æ¯ä¸ªå­—ç¬¦åæ’å…¥ç©ºæ ¼å³å¯ã€‚è€Œç™½è¯æ–‡ä¸­æœ‰å¤§é‡çš„åŒå­—è¯ï¼Œç”šè‡³ä¸‰å­—è¯ã€å››å­—è¯ï¼Œå¿…é¡»ä½¿ç”¨ä¸“é—¨çš„åˆ†è¯å¼•æ“ï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨äº† [THULAC](http://thulac.thunlp.org/)ï¼Œç›´æ¥é€šè¿‡ `pip install thualac` å°±èƒ½å®‰è£…ã€‚

```py
import thulac

# å¯¹æ–‡è¨€æ–‡æœ¬åˆ†è¯
with open('dataset/source_raw.txt', 'r', encoding='utf-8') as f:
    # ç›®æ ‡æ˜¯ ç™½è¯->æ–‡è¨€ï¼Œå› æ­¤å°†æ–‡è¨€ä½œä¸ºç›®æ ‡ target.txt
    with open('dataset/target.txt', 'w+', encoding='utf-8') as s:
        print("separating wenyan text...")
        while True:
            line = f.readline()
            if line:
                line_seq = " ".join([char for char in line])
                s.write(line_seq)
            else:
                break

# å¯¹ç™½è¯æ–‡æœ¬åˆ†è¯ï¼Œå°†ç™½è¯ä½œä¸ºæºè¯­è¨€ source.txt
print("separating modern text...")
sep_model = thulac.thulac(seg_only=True)
sep_model.cut_f('dataset/target_raw.txt', 'dataset/source.txt')
```

- ä½¿ç”¨ `thulac` é¦–å…ˆè¦åŠ è½½åˆ†è¯æ¨¡å‹ï¼Œ`seg_only` æŒ‡å®šåªåˆ†è¯ï¼Œä¸è¾“å‡ºè¯æ€§
- `cut_f(input, output)` ç”¨äºå¯¹æ–‡ä»¶ `input` åˆ†è¯ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ° `output`

{note begin}ä½¿ç”¨ thulac å¤„ç†æ–‡ä»¶æ—¶ä¸€èˆ¬ä¼šè¾“å‡º `UnicodeDecodeError` é”™è¯¯ï¼Œä¸»è¦æ˜¯è¯»å–æ–‡ä»¶æ—¶çš„ç¼–ç é”™è¯¯ï¼Œæ˜¯ thulac æœ¬èº«çš„ä¸€ä¸ª bugï¼Œè¯·çœ‹ä¸‹æ–‡çš„è§£å†³æ–¹æ³•<del>ï¼ˆä¹Ÿå¯èƒ½å®˜æ–¹ä¿®å¥½äº†ï¼‰</del>ã€‚

æ‰¾åˆ°é”™è¯¯ä¿¡æ¯ä¸­çš„ `site-packages\thulac\__init__.py` æ–‡ä»¶ï¼Œç¬¬ 187 è¡Œä¸ç¬¬ 188 è¡Œçš„ä»£ç ä¸º

```py
input_f = open(input_file, 'r')
output_f = open(output_file, 'w')
```

å°†å…¶ä¿®æ”¹ä¸º

```py
input_f = open(input_file, 'r', encoding='utf-8')
output_f = open(output_file, 'w', encoding='utf-8')
```

{note end}

åŒæ ·å†æ£€æŸ¥ä¸€ä¸‹å¤„ç†çš„ç»“æœï¼š

```txt
# dataset/source.txt
æå¯† çš„ æ„è§ æ²¡æœ‰ è¢« é‡‡çº³ ã€‚
æŠ¼é€ çš„ äºº è´ªå›¾ é‡‘é’± ï¼Œ ä¾¿ æ»¡å£ç­”åº” ã€‚
æ´¾ äºº æ¸¸è¯´ å° è‚¡ä¹‰å†› ï¼Œ è¢« åŠè¯´ çš„ äºº éƒ½ å½’é¡º äº† ç¿Ÿè®© ï¼Œ ç¿Ÿè®© å¼€å§‹ çœ‹é‡ äº† ä»– ï¼Œ å« ä»– åŒ è‡ªå·± ä¸€èµ· è®¨è®º é‡å¤§ é—®é¢˜ ã€‚
å®‡æ–‡ æ¸©å¸¸ å¯¹ æå¯† è¯´ ï¼š ä¸ æ€ é‚´å…ƒçœŸ ï¼Œ æ‚¨ çš„ ç¥¸å®³ å°± ä¸ ä¼š æ’é™¤ ã€‚

# dataset/target.txt
å¯† è®¡ ä¸ è¡Œ ã€‚
ä½¿ è€… åˆ© é‡‘ ï¼Œ é‚ ç›¸ è®¸ ã€‚
é£ è¯´ è¯¸ å° è´¼ ï¼Œ æ‰€ è‡³ è¾„ é™ ï¼Œ è®© å§‹ æ•¬ ç„‰ ï¼Œ å¬ ä¸ è®¡ äº‹ ã€‚
å®‡ æ–‡ æ¸© æ¯ è°“ å¯† æ›° ï¼š ä¸ æ€ å…ƒ çœŸ ï¼Œ å…¬ éš¾ æœª å·² ã€‚
```

åˆ†è¯ç»“æœè™½ç„¶æœ‰é”™è¯¯ï¼Œä½†æ€»ä½“æ•ˆæœè¿˜å¯ä»¥ï¼Œæœ€åå°†å…¨éƒ¨æ–‡æœ¬åˆ’åˆ†ä¸ºè®­ç»ƒé›†ä¸éªŒè¯é›†ã€‚ç”±äºæ–‡æœ¬æ•°æ®éå¸¸å¤§ï¼Œä¸é€‚åˆè¯»å–åè½¬æ¢ä¸ºåˆ—è¡¨è¿›è¡Œæ“ä½œï¼Œæˆ‘å†™äº†ä¸€ä¸ªåˆ’åˆ† `.txt` æ–‡æœ¬çš„è„šæœ¬ï¼Œå¯ä»¥åœ¨ GitHub ä¸Šæ‰¾åˆ°ï¼Œä»£ç ä¸å¤æ‚ï¼Œå°±ä¸å±•å¼€ä»‹ç»äº†ã€‚åˆ’åˆ†æ•°æ®é›†åçš„æ–‡ä»¶ç»“æ„ä¸ OpenNMT è¦æ±‚çš„æ•°æ®ä¸€è‡´ï¼Œå°±å¯ä»¥ç›´æ¥ä½¿ç”¨äº†ã€‚

```sh
dataset
â”œâ”€â”€ src-train.txt
â”œâ”€â”€ src-val.txt
â”œâ”€â”€ source.txt
â”œâ”€â”€ source_raw.txt
â”œâ”€â”€ target.txt
â”œâ”€â”€ target_raw.txt
â”œâ”€â”€ tgt-train.txt
â””â”€â”€ tgt-val.txt
```

### æ„å»ºè¯åº“

åŒæ ·åˆ›å»º `.yaml` é…ç½®æ–‡ä»¶ï¼Œå†…å®¹ä¸º

```yaml
# wenyan.yaml

## Where the samples will be written
save_data: run/wenyan
## Where the vocab(s) will be written
src_vocab: run/wenyan.vocab.src
tgt_vocab: run/wenyan.vocab.tgt
src_vocab_size: 200000
tgt_vocab_size: 200000
overwrite: True

# Corpus opts:
data:
    corpus_1:
        path_src: dataset/src-train.txt
        path_tgt: dataset/tgt-train.txt
    valid:
        path_src: dataset/src-val.txt
        path_tgt: dataset/tgt-val.txt

# Train on a single GPU
world_size: 1
gpu_ranks: [0]
queue_size: 100
bucket_size: 2048

# Train batch
batch_size: 32
# Validation batch
valid_batch_size: 16

# Where to save the checkpoints
save_model: run/model
save_checkpoint_steps: 10000
train_steps: 1000000
valid_steps: 10000
```

- `queue_size` ä¸ºè¯»å–æ•°æ®çš„æ¶ˆæ¯é˜Ÿåˆ—å¤§å°
- `bucket_size` ä¸ºè¯»å–æ•°æ®çš„ç¼“å†²åŒºå¤§å°ï¼Œç”¨äºé¿å…æ— æ³•å®æ—¶è¯»å–æ•°æ®
- `batch_size` ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†çš„æ‰¹å¤§å°
- `valid_batch_size` ä¸ºéªŒè¯è¿‡ç¨‹ä¸­å¤„ç†çš„æ‰¹å¤§å°

```sh
onmt_build_vocab -config wenyan.yaml -n_sample -1
```

åŒæ ·ä½¿ç”¨è¯¥å‘½ä»¤å¼€å§‹æ„å»ºè¯åº“ï¼Œå°† `-n_sample` æŒ‡å®šä¸º `-1` èƒ½è®©æ¨¡å‹ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„æ•°æ®æ„å»ºè¯åº“ã€‚å¯ä»¥ä½¿ç”¨ `head run/wenyan.vocab.src` æŸ¥çœ‹ä¸€ä¸‹æ„å»ºçš„è¯åº“ï¼š

```txt
ï¼Œ      2041007
ã€‚      920182
çš„      700401
ä¸      279935
ã€      224914
äº†      195770
æ˜¯      176242
ä»–      175822
åœ¨      156216
è¯´      143227
```

### è®­ç»ƒæ¨¡å‹

ä½¿ç”¨ `onmt_train -config wenyan.yaml` å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚

ç”±äºæ•°æ®é›†å¾ˆå¤§ï¼Œè®­ç»ƒæ¨¡å‹éœ€è¦éå¸¸é•¿çš„æ—¶é—´ï¼Œä¸­é€”å¯èƒ½è®­ç»ƒä¸­æ–­æˆ–å¡æ­»ã€‚ç”±äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜äº† `checkpoints`ï¼Œä¹Ÿä¸éœ€è¦é‡å¤´è®­ç»ƒï¼Œå¯ä»¥ä»ä¿å­˜çš„æ–­ç‚¹ç»§ç»­è®­ç»ƒã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹çš„è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œå°†å…¶ä¿å­˜ä¸º `train.py`ï¼Œå°±å¯ä»¥é€šè¿‡ `python train.py` è‡ªåŠ¨ç»§ç»­è®­ç»ƒã€‚

```py
import os

model_root = 'run/wenyan'
try:
    checkpoints = [x for x in os.listdir(model_root) if x.endswith('.pt')]
except FileNotFoundError:
    os.mkdir(model_root)
    checkpoints = [x for x in os.listdir(model_root) if x.endswith('.pt')]

last_checkpoint = None
if len(checkpoints) > 0:
    checkpoints = sorted(checkpoints, key=lambda x: int(x[:-3].split('_')[-1]))
    last_checkpoint = checkpoints[-1]
    last_checkpoint = os.path.join(model_root, last_checkpoint)

if last_checkpoint is not None:
    print('last_checkpoint', last_checkpoint, os.path.exists(last_checkpoint))
    if isinstance(last_checkpoint, str) and os.path.exists(last_checkpoint):
        # ä¸­æ–­åç»§ç»­è®­ç»ƒä½¿ç”¨
        os.system('onmt_train -config wenyan.yaml --train_from="%s"' % last_checkpoint)
    else:
        os.system('onmt_train -config wenyan.yaml')
else:
    os.system('onmt_train -config wenyan.yaml')
```

åœ¨ `.yaml` æ–‡ä»¶ä¸­æ·»åŠ  `log_file` å¯ä»¥å°†æ—¥å¿—æ–‡ä»¶ä¿å­˜åˆ°ç›¸åº”ç›®å½•ï¼Œè¿™é‡Œæˆ‘æ²¡æœ‰æ·»åŠ ï¼Œç›´æ¥ç”¨ç»ˆç«¯ä¸­çš„è¾“å‡ºæ•°æ®åˆ†æã€‚

![!n](https://storage.live.com/items/4D18B16B8E0B1EDB!8277?authkey=ALYpzW-ZQ_VBXTU)

ACC å’Œ PPL æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å¸¸ç”¨çš„æŒ‡æ ‡ï¼Œå½“ç„¶è¿˜æœ‰æ›´å¥½ç”¨çš„ BELU ç­‰æŒ‡æ ‡ã€‚å¯ä»¥çœ‹å‡ºè®­ç»ƒè¿‡ç¨‹æ”¶æ•›å¾—éå¸¸å¿«ï¼ŒPPL è¿…é€Ÿä¸‹é™ï¼ŒACC ä¹Ÿåœ¨ç¬¬ 20 ä¸ªæ¨¡å‹åä¿æŒç¨³å®šäº†ï¼Œæ£€æŸ¥ä¸€ä¸‹æ—¥å¿—æ–‡ä»¶å‘ç°æœç„¶åœ¨ç¬¬ 23 ä¸ªæ¨¡å‹åå­¦ä¹ ç‡å˜æˆ 0 äº†ã€‚è¿™å°±è¯´æ˜ä¸éœ€è¦æŒ‡å®šé‚£ä¹ˆå¤šçš„è®­ç»ƒæ­¥éª¤ï¼Œé™ä½åˆ° 300000 å¯èƒ½æ˜¯æ¯”è¾ƒåˆé€‚çš„ã€‚

### æ¨¡å‹é¢„æµ‹

é‚£ä¹ˆå°±é€‰æœ€åä¸€ä¸ªæ¨¡å‹ä½œä¸ºæœ€ç»ˆç”¨äºé¢„æµ‹çš„æ¨¡å‹ï¼Œå°†å…¶ä»–æ¨¡å‹å…¨éƒ¨åˆ é™¤ã€‚

{note begin}å¯ä»¥åœ¨ `.yaml` æ–‡ä»¶ä¸­é€šè¿‡å‚æ•° `keep_checkpoint` æŒ‡å®šéœ€è¦ä¿å­˜çš„æ¨¡å‹æ•°é‡ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨åˆ å»å¤šä½™çš„æ¨¡å‹ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ã€‚{note end}

åœ¨ç›®å½•ä¸­æ–°å»ºä¸€ä¸ªæ–‡æœ¬ `input.txt`ï¼Œå†™å…¥éœ€è¦ç¿»è¯‘çš„è¯­å¥ï¼Œæ¯è¡Œä¸€å¥è¯ï¼š

```txt
è¿™æ ·çš„äº‹æƒ…æ˜¯å¾ˆéš¾ä»¤äººç›¸ä¿¡çš„ã€‚
ä¼ è¯´è¥¿åŒ—æ–¹æœ‰ä¸€åº§æµ·å²›ï¼Œå±…ä½ç€ç¥ä»™ï¼Œç•™ä¸‹è¿™éƒ¨ä¹¦ã€‚
å¯æƒœè¿™æœ¬ä¹¦çš„å­—å·²ç»çœ‹ä¸æ¸…äº†ã€‚
åæ¥çš‡å¸ä¸‹æ—¨æ‰¾éäº†å¤©ä¸‹å…·æœ‰æ™ºè¯†çš„å„’ç”Ÿã€‚
å‘½ä»¤å¤§è‡£åœ¨å‡ åå¹´é‡Œç¿»éäº†æ‰€æœ‰çš„è—ä¹¦ã€‚
æœ€åç¡®å®šå°é¢ä¸Šå†™ç€ã€Šç®—æ³•ï¼šCè¯­è¨€å®ç°ã€‹ã€‚
```
{warn begin}æ¯å¥è¯ä»¥æ¢è¡Œï¼ˆ`\n`ï¼‰åˆ†éš”ï¼Œæ³¨æ„æœ€åä¸€è¡Œä¸èƒ½æœ‰ç©ºè¡Œï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚{warn end}

æ¥ç€éœ€è¦å¯¹è¾“å…¥æ–‡æœ¬åˆ†è¯ï¼ŒåŒæ ·ä½¿ç”¨ `thulac`ï¼Œæ–°å»ºä¸€ä¸ª `input_sep.py`ï¼š

```py
import thulac

sep_model = thulac.thulac(seg_only=True)
sep_model.cut_f('input.txt', 'input_sep.txt')
```

è¿è¡Œ `python input_sep.py` å®Œæˆåˆ†è¯åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹ç¿»è¯‘ï¼š

```sh
onmt_translate --model 'run/model_final.pt' --src input_sep.txt --output output.txt
```

ä½¿ç”¨ `cat output.txt` å°±å¯ä»¥çœ‹åˆ°è¾“å‡ºäº†ï¼Œç»“æœéå¸¸ç”Ÿè‰ğŸ¤£

```txt
å¦‚ æ­¤ è€… ï¼Œ éš¾ ä¿¡ ä¹Ÿ ã€‚
ä¼  è¥¿ åŒ— æœ‰ ä¸€ æµ· å²› ï¼Œ å±… ç¥ ä»™ ï¼Œ ç•™ æ­¤ ä¹¦ ã€‚
æƒœ æ­¤ ä¹¦ å·² ä¸ æ˜ çŸ£ ã€‚
å è¯ é é å¤© ä¸‹ æœ‰ çŸ¥ å„’ ç”Ÿ ã€‚
å‘½ å¤§ è‡£ æ•° å å¹´ ï¼Œ å°½ æœ‰ ä¹¦ è— ã€‚
æœ€ å å®š ä¸Š ä¹¦ ã€Š æ³• æœ¯ æ³• ã€‹ ã€‚
```

---

## References

- [OpenNMT-py Documentation](https://opennmt.net/OpenNMT-py/main.html)
- [OpenNMT 2.0.0rc1 ä½¿ç”¨æ‰‹å†Œ - Arabela's Blog](https://arabelatso.github.io/2021/01/03/OpenNMT-Doc/)
- [å¼€æºç¥ç»æœºå™¨ç¿»è¯‘-OpenNMTä½¿ç”¨ä»‹ç» - å“”å“©å“”å“©](https://www.bilibili.com/video/BV1NL4y1t73c/)